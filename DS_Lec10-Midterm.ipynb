{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:5ee7b1e2f637f3f3006a9ff48836ee7badbaa6e5ae5a97f83965e58265629061"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Data Science\n",
      "===================================\n",
      "Midterm Review\n",
      "-----------------------------------\n",
      "Alessandro D. Gagliardi"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Agenda:\n",
      "=======\n",
      "1. Review\n",
      "2. Time Series Analysis\n",
      "3. Regularization\n",
      "4. Lab"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "So Far:\n",
      "=======\n",
      "1. Intro to Data Science\n",
      "2. Python\n",
      "3. Relational Databases\n",
      "4. NoSQL\n",
      "4. APIs\n",
      "5. Probability and Statistics\n",
      "6. Linear Regression\n",
      "7. Logistic Regression and Choice Modeling\n",
      "8. Nine Decades of Machine Learning\n",
      "9. Cross Validation\n",
      "9. Bayes Theorem"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Data Science = Data + Science"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Data can be:\n",
      "------------\n",
      "\n",
      "* **Unstructured** (e.g. Email, Photos, Books, etc.)\n",
      "* **Semi-Structured** (e.g. XML, JSON, NoSQL, APIs, etc.)\n",
      "* **Structured** (e.g. SQL, Data Frames, etc.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Science can be:\n",
      "---------------\n",
      "\n",
      "* **Inferences / Predictions**\n",
      "    - *Statistical Tests* (e.g. t-tests, ANOVA)\n",
      "    - *Supervised Machine Learning* (e.g. Linear Regression, Na\u00efve Bayes, etc.)\n",
      "* **Explorations / Explanations**\n",
      "    - *Data Visualization* (e.g. matplotlib)\n",
      "    - *Unsupervised Machine Learning* (e.g. PCA, clustering, etc.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Data Science Workflow\n",
      "=====================\n",
      "From [a Taxonomy of Data Science](http://www.dataists.com/2010/09/a-taxonomy-of-data-science/) (by Dataists)\n",
      "\n",
      "1. Obtain\n",
      "2. Scrub\n",
      "3. Explore\n",
      "4. Model\n",
      "5. Interpret"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Python\n",
      "----------\n",
      "\n",
      "* **open source**: free! (both like beer and like speech)\n",
      "* **high-level**: interpreted (not compiled)\n",
      "* **dynamic**: things that would typically happen at compile time happen at runtime instead (e.g. dynamic typing)\n",
      "* **scripting language**: \"middle weight\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Third normal form (3NF)\n",
      "-----------------------\n",
      "*\"[Every] non-key [attribute] must provide a fact about the key, the whole key, and nothing but the key (so help me Codd).\"*\n",
      "\n",
      "* Requiring existence of \"the key\" ensures that the table is in 1NF\n",
      "* Requiring that non-key attributes be dependent on \"the whole key\" ensures 2NF\n",
      "* Requiring that non-key attributes be dependent on \"nothing but the key\" ensures 3NF"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## CAP\n",
      "\n",
      "* Consistency\n",
      "    - all nodes always give the same answer\n",
      "* Availability\n",
      "    - nodes always answer queries and accept updates\n",
      "* Partition-tolerance\n",
      "    - system continues working even if one or more nodes go down\n",
      "\n",
      "### CAP Theorem: Pick two"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "APIs\n",
      "----\n",
      "<H3>RESTful web API HTTP methods</H3>\n",
      "<TABLE>\n",
      "<TR><TH>Resource</TH><TH>GET</TH><TH>PUT</TH><TH>POST</TH><TH>DELETE</TH></TR>\n",
      "<TR><TH>Collection URI, such as http://example.com/resources</TH><TD><B>List</B> the URIs and perhaps other details of the collection's members.</TD><TD><B>Replace</B> the entire collection with another collection.</TD><TD><B>Create</B> a new entry in the collection. The new entry's URI is assigned automatically and is usually returned by the operation.</TD><TD><B>Delete</B> the entire collection.</TD></TR>\n",
      "<TR><TH>Element URI, such as http://example.com/resources/item17</TH><TD><B>Retrieve</B> a representation of the addressed member of the collection, expressed in an appropriate Internet media type.</TD><TD><B>Replace</B> the addressed member of the collection, or if it doesn't exist, create it.</TD><TD>Not generally used. Treat the addressed member as a collection in its own right and create a new entry in it.</TD><TD><B>Delete</B> the addressed member of the collection.</TD></TR>\n",
      "</TABLE>\n",
      "\n",
      "<SMALL>*From http://en.wikipedia.org/wiki/Representational_state_transfer*</SMALL>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "What is a regression model?\n",
      "-------------------------------------\n",
      "A **functional relationship** between **input** & **response variables**\n",
      "\n",
      "A **simple linear regression** model captures a linear relationship between an input x and response variable y\n",
      "\n",
      "$$ y = \\alpha + \\beta x + \\epsilon $$\n",
      "\n",
      "$y =$ **response variable** (the one we want to predict)  \n",
      "$x =$ **input variable** (the one we use to train the model)  \n",
      "$\\alpha =$ **intercept** (where the line crosses the y-axis)  \n",
      "$\\beta =$ **regression coefficient** (the model \u201cparameter\u201d)  \n",
      "$\\epsilon =$ **residual** (the prediction error)  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Choice Modeling:\n",
      "==============================\n",
      "Linear Probability Model (LPM)\n",
      "------------------------------\n",
      "\n",
      "* Easy to estimate and interpret (effect of parameters on probability is constant)\n",
      "* Predicted probability is unbounded (not necessarily between 0 and 1)\n",
      "\n",
      "Logistic Regression (Logit)\n",
      "------------------------------\n",
      "\n",
      "* Nonlinear relationship between parameters and estimates (logistic transform)\n",
      "* Values are bounded between zero and one (more realistic)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "What is a p-value?\n",
      "==================\n",
      "What it's not:\n",
      "------------------\n",
      "\n",
      "* It is ***not*** the probability that the null hypothesis is true.\n",
      "* It is ***not*** the inverse of the probability that the alternative hypothesis *is* true.\n",
      "\n",
      "What it is:\n",
      "------------------\n",
      "\n",
      "* The *p-value* is the probability of an observed outcome *if the null hypothesis **were** true*.\n",
      "\n",
      "*N.B. Statistics is incapable of proving that anything is true. It can only suggest that something **probably isn't**.*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "What is Machine Learning?\n",
      "=========================\n",
      "from [Wikipedia](http://en.wikipedia.org/wiki/Machine_learning):\n",
      "\n",
      "> Machine learning, a branch of artificial intelligence, is about the construction and study of systems that can *learn from data*.\u201d\n",
      "\n",
      "\"The core of machine learning deals with *representation* and *generalization*...\"\n",
      "\n",
      "* *representation* \u2013 extracting structure from data\n",
      "* *generalization* \u2013 making predictions from data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "<img src=\"assets/machine_learning3.png\" width=\"800\" />"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Nine Decades of Machine Learning\n",
      "================================\n",
      "*(too much to even summarize but...)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "A view of *statistical data modeling*:\n",
      "--------------------------------------\n",
      "### optimize for: *goodness-of-fit tests, residuals,* etc.\n",
      "\n",
      "A view of *algorithmic modeling*:\n",
      "--------------------------------------\n",
      "### optimize for: *predictive accuracy*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Cross Validation\n",
      "------------------------------------\n",
      "\n",
      "1. Randomly split the dataset into n equal groups\n",
      "2. Use partition 1 as test set & union of other groups as training \n",
      "3. Find generalization error\n",
      "4. Repeat steps 2-3 using different group as test set at each iteration\n",
      "5. Take average generalization error as estimate of OOS accuracy\n",
      "<img src=\"assets/cross-validation.jpg\" width=\"600\"/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Bayes Theorem\n",
      "========================================================\n",
      "$P(AB) = P(A|B) \\times P(B)\\qquad$  \n",
      "$P(BA) = P(B|A) \\times P(A)\\qquad$ by substitution  \n",
      "But $P(AB) = P(BA)\\qquad$ since event $AB =$ event $BA$   \n",
      "$\\hookrightarrow P(A|B) \\times P(B) = P(B|A) \\times P(A)\\>$\tby combining the above  \n",
      "$\\hookrightarrow P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\>$\tby rearranging last step  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Bayesian Inference\n",
      "========================================================\n",
      "$$ P(C | x_1, \\ldots, x_n) = \\frac{P(x_1, \\ldots, x_n | C) \\times P(C)}{P(x_1, \\ldots, x_n)} $$ \n",
      "\n",
      "In plain English the above equation can be written as  \n",
      "\n",
      "$$ \\mbox{posterior} = \\frac{\\mbox{likelihood} \\times \\mbox{prior}}{\\mbox{evidence}} $$\n",
      "\n",
      "Make a simplifying assumption. In particular, we assume that the features $x_1, \\ldots, x_n$ are conditionally independent from each other:\n",
      "\n",
      "$$ P(x_1, \\ldots, x_n | C) \\approx P(x_1 | C) \\times P(x_2 | C) \\times \\ldots \\times P(x_n|C) $$\n",
      "\n",
      "This \"na\u00efve\" assumption simplifies the likelihood function to make it tractable."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Questions?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Time Series Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The main difference between time series analysis and other forms of analysis is that each instance is not independant of each other instance. (e.g. Sales on day $t$ may be related to sales on day $t-1$ while sales by clerk $x$ are (hopefully) independant of sales by clerk $x-1$)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Autoregression\n",
      "--------------\n",
      "\n",
      "The notation AR($p$) refers to the autoregressive model of order $p$. The AR($p$) model is written\n",
      "\n",
      "$$ X_t = c + \\sum_{i=1}^p \\varphi_i X_{t-i}+ \\varepsilon_t .\\, $$\n",
      "\n",
      "where $\\varphi_1, \\ldots, \\varphi_p$ are parameters, $c$ is a constant, and the random variable $\\varepsilon_t$ is white noise."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "Moving Average\n",
      "--------------\n",
      "\n",
      "The notation MA($q$) refers to the moving average model of order $q$:\n",
      "\n",
      "$$ X_t = \\mu + \\varepsilon_t + \\sum_{i=1}^q \\theta_i \\varepsilon_{t-i}\\, $$\n",
      "\n",
      "where the $\\theta_1, \\ldots, \\theta_q$ are the parameters of the model, $\\mu$ is the expectation of $X_t$ (often assumed to equal 0), and the $\\varepsilon_t$, $\\varepsilon_{t-1}$,... are again, white noise error terms. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "The moving-average model is essentially a finite impulse response filter with some additional interpretation placed on it."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "ARMA model\n",
      "--------------\n",
      "The notation ARMA($p, q$) refers to the model with $p$ autoregressive terms and $q$ moving-average terms. This model contains the AR($p$) and MA($q$) models,\n",
      "\n",
      "$$ X_t = c + \\varepsilon_t +  \\sum_{i=1}^p \\varphi_i X_{t-i} + \\sum_{i=1}^q \\theta_i \\varepsilon_{t-i}.\\,$$\n",
      "\n",
      "\n",
      "<small>*(from [Wikipedia](http://en.wikipedia.org/wiki/Autoregressive_moving_average))*</small>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Extensions include:\n",
      "\n",
      "* ARIMA - Autoregressive *integrated* moving average\n",
      "* ARMAX - Autoregressive\u2013moving-average with *exogenous* inputs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "Other time series methods include:\n",
      "\n",
      "* Time Series Principal Component Analysis"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regularization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Recall our earlier discussion of **overfitting**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "It is a result of matching the training set too closely."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "In other words, an overfit model matches the **noise** in the dataset instead of the **signal**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "<img src=\"assets/overfitting_fig.png\" />\n",
      "_source: Data Analysis with Open Source Tools, by Philipp K. Janert. O\u2019Reilly Media, 2011_"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Q:  How do we define the **complexity** of a regression model?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "A:  One method is to define complexity as a function of the size of the coefficients."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Ex 1: $\\sum |\\beta_i|$  \n",
      "Ex 2: $\\sum \\beta_i^2$  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Q:  How do we define the **complexity** of a regression model?  \n",
      "\n",
      "A:  One method is to define complexity as a function of the size of the coefficients.  \n",
      "\n",
      "Ex 1: $\\sum |\\beta_i| \\leftarrow$ this is called the **L1-norm**  \n",
      "Ex 2: $\\sum \\beta_i^2 \\leftarrow$ this is called the **L2-norm**  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "These measures of complexity lead to the following **regularization** techniques:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**L1 regularization**: $y = \\sum \\beta_i x_i + \\epsilon$ such that $\\sum |\\beta_i| < s $"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**L2 regularization**: $y = \\sum \\beta_i x_i + \\epsilon$ such that $\\sum \\beta_i^2 < s $"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**Regularization** refers to the method of preventing **overfitting** by explicitly controlling model **complexity**."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "These regularization problems can also be expressed as:\n",
      "\n",
      "**L1 regularization:** $ \\min(||y - x\\beta||^2 + \\lambda ||x||) $  \n",
      "**L2 regularization:** $ \\min(||y - x\\beta||^2 + \\lambda ||x||^2) $  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "This (Lagrangian) formulation reflects the fact that there is a cost associated with regularization."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "LAB\n",
      "===\n",
      "In the `DAT6` folder, from the command line:\n",
      "```bash\n",
      "git commit -am ...\n",
      "git checkout gh-pages\n",
      "git pull\n",
      "git checkout personal\n",
      "git merge gh-pages\n",
      "ipython notebook\n",
      "```\n",
      "Then open `DS_Lab10-Regularization`"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}