{
 "metadata": {
  "name": "",
  "signature": "sha256:07b3e57bef7bec234a77cc47f9acc3964f73d1a9f6b7bb606d2f693dbf0b30ce"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Homework\n",
      "========\n",
      "\n",
      "1. Read the Na\u00efve Bayes documentation at [scikit-learn.org](http://scikit-learn.org/stable/modules/naive_bayes.html). There are three Na\u00efve Bayes classifiers described. Which of the other two might also be appropriate for this task?\n",
      "2. Explain your choice and apply it to either the spam/ham dataset (if you completed the pair assignment) or the newsgroups dataset (if you didn't).\n",
      "3. Use grid search cross validation to find the best parameters for both the vectorizor and classifier.\n",
      "    - Do different parameters for the vectorizor work better for this classifier?\n",
      "4. Does this classifier do better or worse than the multinomial classifier?\n",
      "5. Advanced: consider the descriptions of the two classifiers in light of which does better for this problem. Can you posit a theory as to why one classifier should do better than the other?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####1. Read the Na\u00efve Bayes documentation at scikit-learn.org. There are three Na\u00efve Bayes classifiers described. Which of the other two might also be appropriate for this task?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Bernoulli Naive Bayes classifier looks like a good fit for the spam/not spam problem.  I've used the newsgroups below b/c of issues w spam so I 'll never know (until Drew publishes the solution)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2a. Explain your choice and... "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Explanation**: \n",
      "    \"BernoulliNB implements the naive Bayes training and classification algorithms for data that is distributed according to multivariate Bernoulli distributions; i.e., there may be multiple features but each one is assumed to be a binary-valued (Bernoulli, boolean) variable.\"\n",
      "\n",
      "Since we are trying to classify docs as spam or not spam we can assume a multivariate Bernoulli distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 2b. ...apply it to either the spam/ham dataset (if you completed the pair assignment) or the newsgroups dataset (if you didn't)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_files\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.pipeline import Pipeline\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the text data\n",
      "categories = [\n",
      "    'alt.atheism',\n",
      "    'talk.religion.misc',\n",
      "    'comp.graphics',\n",
      "    'sci.space',\n",
      "]\n",
      "news_4cat_train = load_files('../../DAT6/datasets/20news-bydate-train/',\n",
      "    categories=categories, encoding='latin-1')\n",
      "news_4cat_test = load_files('../../DAT6/datasets/20news-bydate-test/',\n",
      "    categories=categories, encoding='latin-1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news_4cat_train.target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "array([1, 0, 3, ..., 2, 1, 1])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Turn the text documents into vectors of word frequencies\n",
      "vec = TfidfVectorizer(min_df=2)\n",
      "X_train = vec.fit_transform(news_4cat_train.data)\n",
      "y_train = news_4cat_train.target\n",
      "\n",
      "# Fit two classifier on the training set\n",
      "clfBn = BernoulliNB().fit(X_train, y_train)\n",
      "clfMn = MultinomialNB().fit(X_train, y_train)\n",
      "print(\"Training scoreBn: {0:.1f}%\".format(\n",
      "    clfBn.score(X_train, y_train) * 100))\n",
      "print(\"Training scoreMn: {0:.1f}%\".format(\n",
      "    clfMn.score(X_train, y_train) * 100))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training scoreBn: 90.6%\n",
        "Training scoreMn: 94.9%\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####3a. Use grid search cross validation to find the best parameters for both the vectorizor and classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipelineMn = Pipeline((\n",
      "    ('vec1', TfidfVectorizer()),\n",
      "    ('clfMn', MultinomialNB()),\n",
      "))\n",
      "parametersMn = {\n",
      "    'vec1__max_df': [0.8, 1.0],\n",
      "    'vec1__ngram_range': [(1, 1), (1, 2)],\n",
      "    'clfMn__alpha': np.logspace(-5, 0, 4)\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs_Mn = GridSearchCV(pipelineMn, parametersMn, verbose=2, refit=False, n_jobs=1)\n",
      "_Mn = gs_Mn.fit(news_4cat_train.data, news_4cat_train.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipelineBn = Pipeline((\n",
      "    ('vec2', TfidfVectorizer()),\n",
      "    ('clfBn', BernoulliNB()),\n",
      "))\n",
      "parametersBn = {\n",
      "    'vec2__max_df': [0.8, 1.0],\n",
      "    'vec2__ngram_range': [(1, 1), (1, 2)],\n",
      "    'clfBn__alpha': np.logspace(-5, 0, 4)\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs_Bn = GridSearchCV(pipelineBn, parametersBn, verbose=2, refit=False, n_jobs=2)\n",
      "_Bn = gs_Bn.fit(news_4cat_train.data, news_4cat_train.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=2)]: Done   1 jobs       | elapsed:   38.2s\n",
        "[Parallel(n_jobs=2)]: Done  41 jobs       | elapsed:  3.6min\n",
        "[Parallel(n_jobs=2)]: Done  46 out of  48 | elapsed:  4.0min remaining:   10.3s\n",
        "[Parallel(n_jobs=2)]: Done  48 out of  48 | elapsed:  4.2min finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####3b. Do different parameters for the vectorizor work better for this classifier?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs_Bn.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "{'clfBn__alpha': 1.0000000000000001e-05,\n",
        " 'vec2__max_df': 1.0,\n",
        " 'vec2__ngram_range': (1, 2)}"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs_Mn.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "{'clfMn__alpha': 0.00046415888336127822,\n",
        " 'vec1__max_df': 0.8,\n",
        " 'vec1__ngram_range': (1, 2)}"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####4. Does this classifier do better or worse than the multinomial classifier?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test them\n",
      "X_test = vec.transform(news_4cat_test.data)\n",
      "y_test = news_4cat_test.target\n",
      "# the mean accuracy on the given test data and labels.\n",
      "print(\"Training scoreBn: {0:.1f}%\".format(\n",
      "    clfBn.score(X_test, y_test) * 100))\n",
      "print(\"Training scoreMn: {0:.1f}%\".format(\n",
      "    clfMn.score(X_test, y_test) * 100))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training scoreBn: 78.4%\n",
        "Training scoreMn: 84.9%\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####5. Advanced: consider the descriptions of the two classifiers in light of which does better for this problem. Can you posit a theory as to why one classifier should do better than the other?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the 4 newsgroups, it is not surprising that the Multinomial NB classifier works better;\n",
      "  - Gaussian would be best for predicting continuous depenents vars\n",
      "  - Bernoulli for discrete binary (yes/no)\n",
      "  - Multinomial for fitting into a discrete set of outcomes as we have with the newsgroups"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}