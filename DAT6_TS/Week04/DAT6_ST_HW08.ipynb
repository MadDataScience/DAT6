{
 "metadata": {
  "name": "",
  "signature": "sha256:3067113077b169e23d44b3a8386a5bf507209ae641c008807e4f76dbe34bc429"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lab - Choice Modeling"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pair:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import statsmodels.api as sm\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DS_Lab01-Python-Numpy.html      DS_Lec02-Python-Libraries.pdf\r\n",
        "DS_Lab01-Python-Numpy.ipynb     DS_Lec03-RDBMS.html\r\n",
        "DS_Lab02-Git.pdf                DS_Lec03-RDBMS.ipynb\r\n",
        "DS_Lab02-Python-Pandas.html     DS_Lec03-RDBMS.slides.html\r\n",
        "DS_Lab02-Python-Pandas.ipynb    DS_Lec04-API.html\r\n",
        "DS_Lab03-RDBMS.html             DS_Lec04-API.ipynb\r\n",
        "DS_Lab03-RDBMS.ipynb            DS_Lec04-API.slides.html\r\n",
        "DS_Lab03-RDBMS.slides.html      DS_Lec05-Stats.html\r\n",
        "DS_Lab04-API.html               DS_Lec05-Stats.ipynb\r\n",
        "DS_Lab04-API.ipynb              DS_Lec05-Stats.slides.html\r\n",
        "DS_Lab04-API.slides.html        DS_Lec06-ML.html\r\n",
        "DS_Lab05-Stats.html             DS_Lec06-ML.ipynb\r\n",
        "DS_Lab05-Stats.ipynb            DS_Lec06-ML.slides.html\r\n",
        "DS_Lab06-ML.html                DS_Lec08-ChoiceModelingGA.pdf\r\n",
        "DS_Lab06-ML.ipynb               README.md\r\n",
        "DS_Lab08-Choice Modeling.html   \u001b[34massets\u001b[m\u001b[m/\r\n",
        "DS_Lab08-Choice Modeling.ipynb  \u001b[34mdata\u001b[m\u001b[m/\r\n",
        "DS_Lec01-Intro.html             enron.db\r\n",
        "DS_Lec01-Intro.ipynb            \u001b[34mfonts\u001b[m\u001b[m/\r\n",
        "DS_Lec01-Intro.slides.html      index.html\r\n",
        "DS_Lec01-Python-Intro.pdf       \u001b[34mreveal.js\u001b[m\u001b[m/\r\n",
        "DS_Lec02-Git.pdf\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdata = pd.read_csv('./data/milkdata.csv')\n",
      "mdata.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>product</th>\n",
        "      <th>full_price</th>\n",
        "      <th>full_pri</th>\n",
        "      <th>promo</th>\n",
        "      <th>disc_price</th>\n",
        "      <th>bundle</th>\n",
        "      <th>time_day</th>\n",
        "      <th>repeated?</th>\n",
        "      <th>repeated_bundle?</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1.58</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.42</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1.15</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.85</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2.25</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0.75</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>3 rows \u00d7 10 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "   id  product  full_price  full_pri  promo  disc_price  bundle  time_day  \\\n",
        "0   1        1           2      1.58      1        0.42       1         1   \n",
        "1   2        1           2      1.15      1        0.85       1         1   \n",
        "2   3        1           3      2.25      1        0.75       0         1   \n",
        "\n",
        "   repeated?  repeated_bundle?  \n",
        "0          1                 1  \n",
        "1          0                 1  \n",
        "2          1                 1  \n",
        "\n",
        "[3 rows x 10 columns]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Run a simple logit model where yi = Prob(product i = 1) on all other variables in the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdata.columns[2:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "Index([u'full_price', u'full_pri', u'promo', u'disc_price', u'bundle', u'time_day', u'repeated?', u'repeated_bundle?'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_cols = mdata.columns[2:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit = sm.Logit(mdata[\"product\"], mdata[train_cols])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results=logit.fit()\n",
      "results.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimization terminated successfully.\n",
        "         Current function value: 0.583270\n",
        "         Iterations 5\n"
       ]
      },
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>Logit Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>      <td>product</td>     <th>  No. Observations:  </th>  <td>   500</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   492</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>          <td>Mon, 12 May 2014</td> <th>  Pseudo R-squ.:     </th>  <td>0.09381</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>              <td>13:55:47</td>     <th>  Log-Likelihood:    </th> <td> -291.63</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -321.83</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.266e-10</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>full_price</th>       <td>   -0.8837</td> <td>    0.515</td> <td>   -1.717</td> <td> 0.086</td> <td>   -1.893     0.125</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>full_pri</th>         <td>    0.3279</td> <td>    0.462</td> <td>    0.710</td> <td> 0.478</td> <td>   -0.577     1.233</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>promo</th>            <td>   -0.1351</td> <td>    0.448</td> <td>   -0.301</td> <td> 0.763</td> <td>   -1.014     0.744</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>disc_price</th>       <td>    0.4445</td> <td>    0.559</td> <td>    0.795</td> <td> 0.427</td> <td>   -0.652     1.541</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>bundle</th>           <td>    0.6897</td> <td>    0.259</td> <td>    2.665</td> <td> 0.008</td> <td>    0.183     1.197</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>time_day</th>         <td>    1.3524</td> <td>    0.210</td> <td>    6.449</td> <td> 0.000</td> <td>    0.941     1.763</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>repeated?</th>        <td>    0.6464</td> <td>    0.269</td> <td>    2.401</td> <td> 0.016</td> <td>    0.119     1.174</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>repeated_bundle?</th> <td>    0.2952</td> <td>    0.387</td> <td>    0.763</td> <td> 0.445</td> <td>   -0.463     1.053</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                           Logit Regression Results                           \n",
        "==============================================================================\n",
        "Dep. Variable:                product   No. Observations:                  500\n",
        "Model:                          Logit   Df Residuals:                      492\n",
        "Method:                           MLE   Df Model:                            7\n",
        "Date:                Mon, 12 May 2014   Pseudo R-squ.:                 0.09381\n",
        "Time:                        13:55:47   Log-Likelihood:                -291.63\n",
        "converged:                       True   LL-Null:                       -321.83\n",
        "                                        LLR p-value:                 1.266e-10\n",
        "====================================================================================\n",
        "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------------\n",
        "full_price          -0.8837      0.515     -1.717      0.086        -1.893     0.125\n",
        "full_pri             0.3279      0.462      0.710      0.478        -0.577     1.233\n",
        "promo               -0.1351      0.448     -0.301      0.763        -1.014     0.744\n",
        "disc_price           0.4445      0.559      0.795      0.427        -0.652     1.541\n",
        "bundle               0.6897      0.259      2.665      0.008         0.183     1.197\n",
        "time_day             1.3524      0.210      6.449      0.000         0.941     1.763\n",
        "repeated?            0.6464      0.269      2.401      0.016         0.119     1.174\n",
        "repeated_bundle?     0.2952      0.387      0.763      0.445        -0.463     1.053\n",
        "====================================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. Run the same model with LPM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm = sm.OLS(mdata[\"product\"], mdata[train_cols]).fit()\n",
      "#lm = smf.ols('Y ~ X1 + X2 + X3 + X4 + X5 + X6', data=x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>OLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>         <td>product</td>     <th>  R-squared:         </th> <td>   0.696</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.691</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   140.8</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Mon, 12 May 2014</td> <th>  Prob (F-statistic):</th> <td>5.40e-122</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>13:55:49</td>     <th>  Log-Likelihood:    </th> <td> -306.41</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>   500</td>      <th>  AIC:               </th> <td>   628.8</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   662.5</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>full_price</th>       <td>   -0.1311</td> <td>    0.103</td> <td>   -1.271</td> <td> 0.204</td> <td>   -0.334     0.072</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>full_pri</th>         <td>    0.1709</td> <td>    0.093</td> <td>    1.836</td> <td> 0.067</td> <td>   -0.012     0.354</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>promo</th>            <td>   -0.1002</td> <td>    0.091</td> <td>   -1.102</td> <td> 0.271</td> <td>   -0.279     0.079</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>disc_price</th>       <td>    0.1352</td> <td>    0.112</td> <td>    1.202</td> <td> 0.230</td> <td>   -0.086     0.356</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>bundle</th>           <td>    0.1987</td> <td>    0.052</td> <td>    3.794</td> <td> 0.000</td> <td>    0.096     0.302</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>time_day</th>         <td>    0.3349</td> <td>    0.044</td> <td>    7.691</td> <td> 0.000</td> <td>    0.249     0.420</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>repeated?</th>        <td>    0.1723</td> <td>    0.055</td> <td>    3.136</td> <td> 0.002</td> <td>    0.064     0.280</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>repeated_bundle?</th> <td>    0.1623</td> <td>    0.079</td> <td>    2.056</td> <td> 0.040</td> <td>    0.007     0.317</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td>117.020</td> <th>  Durbin-Watson:     </th> <td>   0.620</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  46.997</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td>-0.567</td>  <th>  Prob(JB):          </th> <td>6.23e-11</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 2.015</td>  <th>  Cond. No.          </th> <td>    31.3</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                product   R-squared:                       0.696\n",
        "Model:                            OLS   Adj. R-squared:                  0.691\n",
        "Method:                 Least Squares   F-statistic:                     140.8\n",
        "Date:                Mon, 12 May 2014   Prob (F-statistic):          5.40e-122\n",
        "Time:                        13:55:49   Log-Likelihood:                -306.41\n",
        "No. Observations:                 500   AIC:                             628.8\n",
        "Df Residuals:                     492   BIC:                             662.5\n",
        "Df Model:                           8                                         \n",
        "====================================================================================\n",
        "                       coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------------\n",
        "full_price          -0.1311      0.103     -1.271      0.204        -0.334     0.072\n",
        "full_pri             0.1709      0.093      1.836      0.067        -0.012     0.354\n",
        "promo               -0.1002      0.091     -1.102      0.271        -0.279     0.079\n",
        "disc_price           0.1352      0.112      1.202      0.230        -0.086     0.356\n",
        "bundle               0.1987      0.052      3.794      0.000         0.096     0.302\n",
        "time_day             0.3349      0.044      7.691      0.000         0.249     0.420\n",
        "repeated?            0.1723      0.055      3.136      0.002         0.064     0.280\n",
        "repeated_bundle?     0.1623      0.079      2.056      0.040         0.007     0.317\n",
        "==============================================================================\n",
        "Omnibus:                      117.020   Durbin-Watson:                   0.620\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               46.997\n",
        "Skew:                          -0.567   Prob(JB):                     6.23e-11\n",
        "Kurtosis:                       2.015   Cond. No.                         31.3\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. Predict y_hat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_hat = np.sum(lm.params*mdata.describe().T[2:][\"mean\"])\n",
      "print y_hat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.650263665171\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3. Plot the distribution of y_hat, is there a problem?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#y hat of all of the element. \n",
      "#use predict method"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm.predict()\n",
      "#for all individual in the sample of 500 observations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([ 0.83252545,  0.64489455,  0.66181458,  0.61317329,  0.74906801,\n",
        "        0.74906801,  0.78543197,  0.78543197,  0.65287724,  0.57680933,\n",
        "        0.78543197,  0.85157185,  0.825213  ,  0.74906801,  0.85157185,\n",
        "        0.78543197,  0.74906801,  0.57680933,  0.65287724,  0.65287724,\n",
        "        0.65287724,  0.85157185,  0.65287724,  0.61317329,  0.85157185,\n",
        "        0.57680933,  0.85157185,  0.45051535,  0.31796062,  0.65287724,\n",
        "        0.31796062,  0.45051535,  0.85157185,  0.31796062,  0.51665523,\n",
        "        0.45051535,  0.51665523,  0.78543197,  0.49029637,  0.67931317,\n",
        "        0.24189271,  0.45051535,  0.71639645,  0.31796062,  0.78543197,\n",
        "        0.78543197,  0.825213  ,  0.825213  ,  0.51665523,  0.78543197,\n",
        "        0.825213  ,  0.51665523,  0.45051535,  0.45051535,  0.85157185,\n",
        "        0.65287724,  0.65287724,  0.31796062,  0.57680933,  0.51665523,\n",
        "        0.31796062,  0.27825667,  0.61317329,  0.24189271,  0.41415139,\n",
        "        0.31796062,  0.41415139,  0.85157185,  0.85157185,  0.45051535,\n",
        "        0.51665523,  0.78543197,  0.61317329,  0.78543197,  0.45051535,\n",
        "        0.27825667,  0.85157185,  0.78543197,  0.85157185,  0.78543197,\n",
        "        0.27825667,  0.78543197,  0.78543197,  0.51665523,  0.51665523,\n",
        "        0.51665523,  0.61317329,  0.49029637,  0.85157185,  0.45051535,\n",
        "        0.78543197,  0.27825667,  0.85157185,  0.85157185,  0.85157185,\n",
        "        0.85157185,  0.78543197,  0.78543197,  0.61317329,  0.82118133,\n",
        "        0.61317329,  0.74906801,  0.48061857,  0.85157185,  0.85157185,\n",
        "        0.78543197,  0.85157185,  0.61317329,  0.85157185,  0.67931317,\n",
        "        0.78543197,  0.825213  ,  0.85157185,  0.61317329,  0.61317329,\n",
        "        0.61317329,  0.85157185,  0.61317329,  0.78543197,  0.78543197,\n",
        "        0.85157185,  0.67931317,  0.78543197,  0.74906801,  0.74906801,\n",
        "        0.57680933,  0.57680933,  0.61317329,  0.74906801,  0.71639645,\n",
        "        0.57680933,  0.67931317,  0.45051535,  0.34439655,  0.67931317,\n",
        "        0.78409805,  0.41415139,  0.27825667,  0.34439655,  0.30854795,\n",
        "        0.56114668,  0.43721669,  0.67647182,  0.36477369,  0.34662657,\n",
        "        0.31105041,  0.61031334,  0.30949146,  0.48687788,  0.63679003,\n",
        "        0.64644236,  0.68791043,  0.49699308,  0.76616049,  0.29140686,\n",
        "        0.81666676,  0.38593927,  0.61784287,  0.33466184,  0.68496169,\n",
        "        0.52058766,  0.6195311 ,  0.41499648,  0.62560849,  0.8670061 ,\n",
        "        0.78149954,  0.83298218,  0.87802638,  0.82547482,  0.80376394,\n",
        "        0.75419575,  0.66227171,  0.63168588,  0.53345743,  0.61774363,\n",
        "        0.33590133,  0.830023  ,  0.87302147,  0.82251563,  0.82501809,\n",
        "        0.666462  ,  0.87838387,  0.6610996 ,  0.63812077,  0.48366658,\n",
        "        0.52845252,  0.82440234,  0.33011541,  0.49081645,  0.51665523,\n",
        "        0.83359793,  0.43124387,  0.83512715,  0.56674418,  0.58364632,\n",
        "        0.88238933,  0.59390181,  0.83441216,  0.51737022,  0.50771789,\n",
        "        0.40132249,  0.83038049,  0.29855673,  0.3226971 ,  0.83798709,\n",
        "        0.4337982 ,  0.33333285,  0.82215814,  0.82940725,  0.5564887 ,\n",
        "        0.31339028,  0.82287312,  0.32117806,  0.5530702 ,  0.92729952,\n",
        "        0.28532947,  0.83333968,  0.74735876,  0.67423645,  0.28425698,\n",
        "        0.37008628,  0.62855652,  0.8132208 ,  0.52773753,  0.62124977,\n",
        "        0.76957898,  0.52845252,  0.66860696,  0.46884731,  0.81806312,\n",
        "        0.7799117 ,  0.27003431,  0.6385775 ,  0.56969292,  0.30000713,\n",
        "        0.33333285,  0.8487119 ,  0.82609057,  0.62427776,  0.48366658,\n",
        "        0.64107996,  0.87159149,  0.46201032,  0.29891422,  0.51558275,\n",
        "        0.51670625,  0.8658716 ,  0.62131857,  0.80936143,  0.83298218,\n",
        "        0.86747585,  0.95122899,  0.87159149,  0.53774735,  0.86908904,\n",
        "        0.48162086,  0.85693426,  0.82511732,  0.48116412,  0.51200781,\n",
        "        0.48187911,  0.74013067,  0.82583231,  0.3226971 ,  0.32098786,\n",
        "        0.86193917,  0.81796745,  0.4879565 ,  0.32082057,  0.45051392,\n",
        "        0.5127228 ,  0.36495854,  0.38423002,  0.62124977,  0.83453039,\n",
        "        0.87373646,  0.53309994,  0.49725134,  0.49949554,  0.82904975,\n",
        "        0.8296655 ,  0.52273262,  0.86372663,  0.81760996,  0.51415277,\n",
        "        0.86336914,  0.86801656,  0.83753036,  0.64794941,  0.84585195,\n",
        "        0.871234  ,  0.83405466,  0.89311457,  0.48815141,  0.4959206 ,\n",
        "        0.23331286,  0.49985303,  0.8597942 ,  0.50950536,  0.48759901,\n",
        "        0.46248008,  0.6138112 ,  0.29829788,  0.86873154,  0.66252957,\n",
        "        0.86837405,  0.63197501,  0.87773134,  0.8185832 ,  0.83753036,\n",
        "        0.84942689,  0.82037067,  0.82833477,  0.8194931 ,  0.37226529,\n",
        "        0.8296655 ,  0.85300183,  0.83798709,  0.83619963,  0.81653748,\n",
        "        0.83073798,  0.8765964 ,  0.60495094,  0.64437447,  0.78328701,\n",
        "        0.48935828,  0.61102833,  0.82797727,  0.66431704,  0.29079111,\n",
        "        0.45222317,  0.5732344 ,  0.62954092,  0.85264433,  0.29487939,\n",
        "        0.62775345,  0.87087651,  0.61712788,  0.44405369,  0.74773409,\n",
        "        0.29426681,  0.5352449 ,  0.83298218,  0.74048816,  0.89653306,\n",
        "        0.86301165,  0.63786251,  0.77641597,  0.74260635,  0.86658658,\n",
        "        0.71013065,  0.57251941,  0.62785269,  0.62203356,  0.83905958,\n",
        "        0.87051901,  0.83252545,  0.87480894,  0.87480894,  0.62785269,\n",
        "        0.33419208,  0.6779018 ,  0.8635876 ,  0.33295259,  0.62356277,\n",
        "        0.3193906 ,  0.31831812,  0.61667115,  0.29651101,  0.30687832,\n",
        "        0.78169917,  0.83324044,  0.56965946,  0.666462  ,  0.82225738,\n",
        "        0.84013206,  0.6087255 ,  0.82466059,  0.6610996 ,  0.86801656,\n",
        "        0.6442974 ,  0.82256566,  0.81929819,  0.8658716 ,  0.8217945 ,\n",
        "        0.64902189,  0.60530843,  0.58022783,  0.88456833,  0.62131857,\n",
        "        0.83431292,  0.61891535,  0.85800674,  0.81965568,  0.62463525,\n",
        "        0.87302147,  0.84820437,  0.74156065,  0.90973729,  0.74260635,\n",
        "        0.62535024,  0.64616194,  0.65932297,  0.87373646,  0.86122418,\n",
        "        0.83282115,  0.62417852,  0.67182441,  0.82303542,  0.63071264,\n",
        "        0.77897031,  0.78185703,  0.40735901,  0.62203356,  0.47758919,\n",
        "        0.37692327,  0.49520561,  0.29712675,  0.86229666,  0.78241416,\n",
        "        0.74156065,  0.64322492,  0.93413651,  0.85550428,  0.81608075,\n",
        "        0.64866439,  0.31796062,  0.81663315,  0.32654047,  0.41110822,\n",
        "        0.42012422,  0.48591078,  0.30684412,  0.28425698,  0.52273262,\n",
        "        0.77863959,  0.66717699,  0.8658716 ,  0.82323062,  0.7464946 ,\n",
        "        0.63132839,  0.83038049,  0.63393008,  0.85162287,  0.84370699,\n",
        "        0.67253939,  0.82144315,  0.84013206,  0.65216226,  0.66967944,\n",
        "        0.75248651,  0.73111137,  0.84370699,  0.78420162,  0.68325244,\n",
        "        0.85192935,  0.60975479,  0.86444162,  0.67641545,  0.63107013,\n",
        "        0.63428758,  0.62249029,  0.68107344,  0.61595616,  0.63240087,\n",
        "        0.63168588,  0.82930801,  0.82225738,  0.83834459,  0.62739596,\n",
        "        0.62427776,  0.62739596,  0.86622909,  0.81929819,  0.62999765,\n",
        "        0.86063886,  0.31295571,  0.3146192 ,  0.62346353,  0.67182441,\n",
        "        0.84477947,  0.65180476,  0.62918343,  0.64735824,  0.63919325,\n",
        "        0.86765906,  0.6553797 ,  0.62070282,  0.8544318 ,  0.82180064,\n",
        "        0.63526082,  0.48097606,  0.49742076,  0.66056247,  0.53768697,\n",
        "        0.35190392,  0.63490333,  0.48984321,  0.65009437,  0.48402407])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(lm.predict())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 0.832525</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 0.644895</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 0.661815</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 0.613173</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 0.749068</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 0.749068</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 0.785432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 0.785432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 0.652877</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 0.576809</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 0.785432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 0.851572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 0.825213</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 0.749068</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 0.851572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 0.785432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 0.749068</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 0.576809</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 0.652877</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 0.652877</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> 0.652877</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td> 0.851572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> 0.652877</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td> 0.613173</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td> 0.851572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td> 0.576809</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td> 0.851572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td> 0.450515</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td> 0.317961</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td> 0.652877</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>30</th>\n",
        "      <td> 0.317961</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>31</th>\n",
        "      <td> 0.450515</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>32</th>\n",
        "      <td> 0.851572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>33</th>\n",
        "      <td> 0.317961</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>34</th>\n",
        "      <td> 0.516655</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>35</th>\n",
        "      <td> 0.450515</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>36</th>\n",
        "      <td> 0.516655</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>37</th>\n",
        "      <td> 0.785432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>38</th>\n",
        "      <td> 0.490296</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39</th>\n",
        "      <td> 0.679313</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>40</th>\n",
        "      <td> 0.241893</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>41</th>\n",
        "      <td> 0.450515</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>42</th>\n",
        "      <td> 0.716396</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43</th>\n",
        "      <td> 0.317961</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>44</th>\n",
        "      <td> 0.785432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>45</th>\n",
        "      <td> 0.785432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>46</th>\n",
        "      <td> 0.825213</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>47</th>\n",
        "      <td> 0.825213</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>48</th>\n",
        "      <td> 0.516655</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>49</th>\n",
        "      <td> 0.785432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50</th>\n",
        "      <td> 0.825213</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>51</th>\n",
        "      <td> 0.516655</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>52</th>\n",
        "      <td> 0.450515</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>53</th>\n",
        "      <td> 0.450515</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>54</th>\n",
        "      <td> 0.851572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>55</th>\n",
        "      <td> 0.652877</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>56</th>\n",
        "      <td> 0.652877</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>57</th>\n",
        "      <td> 0.317961</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>58</th>\n",
        "      <td> 0.576809</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>59</th>\n",
        "      <td> 0.516655</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>500 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "           0\n",
        "0   0.832525\n",
        "1   0.644895\n",
        "2   0.661815\n",
        "3   0.613173\n",
        "4   0.749068\n",
        "5   0.749068\n",
        "6   0.785432\n",
        "7   0.785432\n",
        "8   0.652877\n",
        "9   0.576809\n",
        "10  0.785432\n",
        "11  0.851572\n",
        "12  0.825213\n",
        "13  0.749068\n",
        "14  0.851572\n",
        "15  0.785432\n",
        "16  0.749068\n",
        "17  0.576809\n",
        "18  0.652877\n",
        "19  0.652877\n",
        "20  0.652877\n",
        "21  0.851572\n",
        "22  0.652877\n",
        "23  0.613173\n",
        "24  0.851572\n",
        "25  0.576809\n",
        "26  0.851572\n",
        "27  0.450515\n",
        "28  0.317961\n",
        "29  0.652877\n",
        "30  0.317961\n",
        "31  0.450515\n",
        "32  0.851572\n",
        "33  0.317961\n",
        "34  0.516655\n",
        "35  0.450515\n",
        "36  0.516655\n",
        "37  0.785432\n",
        "38  0.490296\n",
        "39  0.679313\n",
        "40  0.241893\n",
        "41  0.450515\n",
        "42  0.716396\n",
        "43  0.317961\n",
        "44  0.785432\n",
        "45  0.785432\n",
        "46  0.825213\n",
        "47  0.825213\n",
        "48  0.516655\n",
        "49  0.785432\n",
        "50  0.825213\n",
        "51  0.516655\n",
        "52  0.450515\n",
        "53  0.450515\n",
        "54  0.851572\n",
        "55  0.652877\n",
        "56  0.652877\n",
        "57  0.317961\n",
        "58  0.576809\n",
        "59  0.516655\n",
        "         ...\n",
        "\n",
        "[500 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(lm.predict()).hist()\n",
      "#yes, there is problem. It's not normally distributed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "array([[<matplotlib.axes.AxesSubplot object at 0x1084d84d0>]], dtype=object)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEKCAYAAAD3tSVSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIU9EFMI45ImIQhiHPBFRCPt/eWkobG3blokAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1084d8150>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.stats import norm\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "WRONG\n",
      "#y_hat_std = np.std(y_hat)\n",
      "#y_hat_mean = np.mean(y_hat)\n",
      "#plt.plot(norm.pdf(y_hat,y_hat_std,y_hat_mean))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'WRONG' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-22-c59513f091d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWRONG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#y_hat_std = np.std(y_hat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#y_hat_mean = np.mean(y_hat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.plot(norm.pdf(y_hat,y_hat_std,y_hat_mean))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'WRONG' is not defined"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "4. Plot the distribution of y_hat from the logit model, is there a problem?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(results.predict()).hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "array([[<matplotlib.axes.AxesSubplot object at 0x108492790>]], dtype=object)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEKCAYAAAD3tSVSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8kREYYxDnogojHHIExGFsf8H0YdiTBek6dcAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1084966d0>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Homework: (or if we have time in class)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1. Run the next logit model:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "y = bundel (if buyera are buying milk in bundels)\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "x = product, full_price, full_pri, promo, disc_pricem, time_day, repeated"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdata.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>product</th>\n",
        "      <th>full_price</th>\n",
        "      <th>full_pri</th>\n",
        "      <th>promo</th>\n",
        "      <th>disc_price</th>\n",
        "      <th>bundle</th>\n",
        "      <th>time_day</th>\n",
        "      <th>repeated?</th>\n",
        "      <th>repeated_bundle?</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 500.000000</td>\n",
        "      <td> 500.000000</td>\n",
        "      <td> 500.000000</td>\n",
        "      <td> 500.000000</td>\n",
        "      <td> 500.000000</td>\n",
        "      <td> 500.000000</td>\n",
        "      <td> 500.000000</td>\n",
        "      <td> 500.000000</td>\n",
        "      <td> 500.00000</td>\n",
        "      <td> 500.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td> 250.500000</td>\n",
        "      <td>   0.656000</td>\n",
        "      <td>   2.490000</td>\n",
        "      <td>   2.022760</td>\n",
        "      <td>   0.582000</td>\n",
        "      <td>   0.554360</td>\n",
        "      <td>   0.622000</td>\n",
        "      <td>   0.704000</td>\n",
        "      <td>   0.77600</td>\n",
        "      <td>   0.748000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td> 144.481833</td>\n",
        "      <td>   0.475517</td>\n",
        "      <td>   0.500401</td>\n",
        "      <td>   0.513379</td>\n",
        "      <td>   0.493724</td>\n",
        "      <td>   0.562047</td>\n",
        "      <td>   0.485373</td>\n",
        "      <td>   0.456948</td>\n",
        "      <td>   0.41734</td>\n",
        "      <td>   0.434596</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  -1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.00000</td>\n",
        "      <td>   0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td> 125.750000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   1.630000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.00000</td>\n",
        "      <td>   0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 250.500000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.480000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.00000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 375.250000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>   2.400000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.00000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 500.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.00000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 10 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "               id     product  full_price    full_pri       promo  disc_price  \\\n",
        "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
        "mean   250.500000    0.656000    2.490000    2.022760    0.582000    0.554360   \n",
        "std    144.481833    0.475517    0.500401    0.513379    0.493724    0.562047   \n",
        "min      1.000000    0.000000    2.000000    1.000000    0.000000   -1.000000   \n",
        "25%    125.750000    0.000000    2.000000    1.630000    0.000000    0.000000   \n",
        "50%    250.500000    1.000000    2.000000    2.000000    1.000000    0.480000   \n",
        "75%    375.250000    1.000000    3.000000    2.400000    1.000000    1.000000   \n",
        "max    500.000000    1.000000    3.000000    3.000000    1.000000    2.000000   \n",
        "\n",
        "           bundle    time_day  repeated?  repeated_bundle?  \n",
        "count  500.000000  500.000000  500.00000        500.000000  \n",
        "mean     0.622000    0.704000    0.77600          0.748000  \n",
        "std      0.485373    0.456948    0.41734          0.434596  \n",
        "min      0.000000    0.000000    0.00000          0.000000  \n",
        "25%      0.000000    0.000000    1.00000          0.000000  \n",
        "50%      1.000000    1.000000    1.00000          1.000000  \n",
        "75%      1.000000    1.000000    1.00000          1.000000  \n",
        "max      1.000000    1.000000    1.00000          1.000000  \n",
        "\n",
        "[8 rows x 10 columns]"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdata.columns[1:6]+mdata.columns[7:9]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "Index([u'disc_price', u'full_pri', u'full_price', u'product', u'promo', u'repeated?', u'time_day'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_cols_1 =  mdata.columns[1:6]+mdata.columns[7:9]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_1 = sm.Logit(mdata[\"bundle\"], mdata[train_cols_1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_1=logit_1.fit()\n",
      "results_1.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimization terminated successfully.\n",
        "         Current function value: 0.640931\n",
        "         Iterations 5\n"
       ]
      },
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>Logit Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>      <td>bundle</td>      <th>  No. Observations:  </th>  <td>   500</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   493</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>          <td>Mon, 12 May 2014</td> <th>  Pseudo R-squ.:     </th>  <td>0.03340</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>              <td>13:59:05</td>     <th>  Log-Likelihood:    </th> <td> -320.47</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -331.54</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>0.001139</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>disc_price</th> <td>   -1.6529</td> <td>    0.535</td> <td>   -3.089</td> <td> 0.002</td> <td>   -2.702    -0.604</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>full_pri</th>   <td>   -1.1878</td> <td>    0.431</td> <td>   -2.757</td> <td> 0.006</td> <td>   -2.032    -0.344</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>full_price</th> <td>    1.5986</td> <td>    0.489</td> <td>    3.270</td> <td> 0.001</td> <td>    0.640     2.557</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>product</th>    <td>    0.5589</td> <td>    0.207</td> <td>    2.696</td> <td> 0.007</td> <td>    0.153     0.965</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>promo</th>      <td>    0.1976</td> <td>    0.351</td> <td>    0.562</td> <td> 0.574</td> <td>   -0.491     0.886</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>repeated?</th>  <td>   -0.4511</td> <td>    0.264</td> <td>   -1.708</td> <td> 0.088</td> <td>   -0.969     0.067</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>time_day</th>   <td>   -0.3666</td> <td>    0.218</td> <td>   -1.682</td> <td> 0.093</td> <td>   -0.794     0.061</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                           Logit Regression Results                           \n",
        "==============================================================================\n",
        "Dep. Variable:                 bundle   No. Observations:                  500\n",
        "Model:                          Logit   Df Residuals:                      493\n",
        "Method:                           MLE   Df Model:                            6\n",
        "Date:                Mon, 12 May 2014   Pseudo R-squ.:                 0.03340\n",
        "Time:                        13:59:05   Log-Likelihood:                -320.47\n",
        "converged:                       True   LL-Null:                       -331.54\n",
        "                                        LLR p-value:                  0.001139\n",
        "==============================================================================\n",
        "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "disc_price    -1.6529      0.535     -3.089      0.002        -2.702    -0.604\n",
        "full_pri      -1.1878      0.431     -2.757      0.006        -2.032    -0.344\n",
        "full_price     1.5986      0.489      3.270      0.001         0.640     2.557\n",
        "product        0.5589      0.207      2.696      0.007         0.153     0.965\n",
        "promo          0.1976      0.351      0.562      0.574        -0.491     0.886\n",
        "repeated?     -0.4511      0.264     -1.708      0.088        -0.969     0.067\n",
        "time_day      -0.3666      0.218     -1.682      0.093        -0.794     0.061\n",
        "==============================================================================\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2. Are consumer more likley to buy 2% milk vs. fat-milk? yes or no? explain"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_hat_logit = sum(results_1.params*mdata[train_cols_1].mean())\n",
      "print y_hat_logit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.534899087583\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3. Is the effect of promotion negative or positive on the outcome (Ignore significance)? Can promotions drive consumer to buy in boundle?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "4. Calculate the odds ratio for this regression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5. Can you think, with the results we got from this regression, about a strategy to convert consumers to buy halthier milk (2%) rather than fat-milk? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}