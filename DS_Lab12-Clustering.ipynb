{
 "metadata": {
  "name": "",
  "signature": "sha256:f3ebe0b80bdd6d6667bd61c5c4ec76cee872056ce701f749322e39ab610bad9b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lab\n",
      "==========================================\n",
      "Clustering\n",
      "------------------------------------------\n",
      "Alessandro D. Gagliardi"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import sklearn.datasets as datasets\n",
      "\n",
      "from sklearn.preprocessing import scale\n",
      "\n",
      "plt.jet() # set the color map. When your colors are lost, re-run this."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For our first example, let's create some synthetic easy-to-cluster data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = datasets.make_blobs(centers=4, cluster_std=0.5, random_state=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As always, we first *plot* the data to get a feeling of what we're dealing with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(X[:,0], X[:,1]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data looks like it may contain four different \"types\" of data point. \n",
      "\n",
      "In fact, this is how it was created above.\n",
      "\n",
      "We can plot this information as well, using color:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(X[:,0], X[:,1], c=Y);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, if you do not know the information in `Y`, you could try to recover it from the data alone.\n",
      "\n",
      "Using hierarchical clustering, we start with a distance matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute distance matrix\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "\n",
      "# not printed as pretty, but the values are correct\n",
      "distx = squareform(pdist(X, metric='euclidean'))\n",
      "distx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We then use `scipy.cluster.hierarchy.linkage` to create the hierarchy, and `...dendrogram` to plot it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# perform clustering and plot the dendrogram\n",
      "from scipy.cluster.hierarchy import linkage, dendrogram\n",
      "\n",
      "R = dendrogram(linkage(distx, method='single'), color_threshold=10)\n",
      "\n",
      "plt.xlabel('points')\n",
      "plt.ylabel('Height')\n",
      "plt.suptitle('Cluster Dendrogram', fontweight='bold', fontsize=14);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`linkage` supports other methods such as [Ward's](http://en.wikipedia.org/wiki/Ward%27s_method):\n",
      "\n",
      "$$ d(u,v) = \\sqrt{\\frac{|v|+|s|}\n",
      "                       {T}d(v,s)^2\n",
      "                + \\frac{|v|+|t|}\n",
      "                       {T}d(v,t)^2\n",
      "                + \\frac{|v|}\n",
      "                       {T}d(s,t)^2}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "R = dendrogram(linkage(distx, method='ward'), color_threshold=100)\n",
      "\n",
      "plt.xlabel('points')\n",
      "plt.ylabel('Height')\n",
      "plt.suptitle('Cluster Dendrogram', fontweight='bold', fontsize=14);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "scikit-learn supports [Ward's method](http://en.wikipedia.org/wiki/Ward%27s_method) as an unsupervised learning method. However (as with kMeans), you must specify how many clusters you want to get out:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import Ward\n",
      "\n",
      "hierarch = Ward(4)\n",
      "Y_hat_hier = hierarch.fit(X).labels_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now the label assignments should be quite similar to `Y`, up to a different ordering of the colors:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(X[:,0], X[:,1], c=Y_hat_hier);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can do the same using `KMeans`.\n",
      "\n",
      "Note that `KMeans` takes an optional `random_state` argument but `Ward` does not. This is because hierarchical clustering is deterministic while k-Means involves a random element (for picking initial centroids)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import KMeans\n",
      "\n",
      "kmeans = KMeans(4, random_state=1)\n",
      "Y_hat_kmeans = kmeans.fit(X).labels_\n",
      "\n",
      "plt.scatter(X[:,0], X[:,1], c=Y_hat_kmeans);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Often, you're not so much interested in the assignments to the means. \n",
      "\n",
      "You'll want to have a closer look at the means $\\mu$.\n",
      "\n",
      "The means in $\\mu$ can be seen as *representatives* of their respective cluster."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(X[:,0], X[:,1], c=Y_hat_kmeans, alpha=0.4)\n",
      "mu = kmeans.cluster_centers_\n",
      "plt.scatter(mu[:,0], mu[:,1], s=100, c=np.unique(Y_hat_kmeans))\n",
      "print mu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1-2 Pairs\n",
      "=========\n",
      "\n",
      "1. Follow the steps below to:\n",
      "    - Read `samsungData.csv` and drop `Unnamed: 0` from the data set.\n",
      "    - Load data for `subject 1` \n",
      "    - Plot the first two variables to see how they relate to the six activities provided.\n",
      "2. Try hierarchical clustering on the first three variables and compare that to the activities.\n",
      "    - Try both single linkage and Ward's method.\n",
      "3. Try hierarchical clustering on variables 9 and 10 and do the same.\n",
      "    - Try Ward's, single, and complete linkage methods.\n",
      "4. Try using all columns (except `subject` and `activity`). This time scale your values first.\n",
      "5. Try `KMeans` where `n_clusters = 6` and compare the clusters to the `activity` column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samsungData = pd.read_csv('data/samsungData.csv')\n",
      "samsungData = samsungData.drop(['Unnamed: 0'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A quick look on the column names and the type of activities in the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samsungData.columns[:12]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samsungData['activity'].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The scatter plots below show the first and second variable/feature vectors for subject number 1, colour coded by activity. We see that almost all activities have the first and second variable values around zero, except for LAYING, which is spread throughout the y-axis.\n",
      "\n",
      "The conclusion from these plots is that we can't really classify the activities based on the two variables, since their values are very close to each other."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subj1 = samsungData[samsungData['subject'] == 1]\n",
      "\n",
      "numericActivity = subj1.groupby('activity')\n",
      "\n",
      "cols = {'laying' : 'b',\n",
      "        'sitting' : 'g',\n",
      "        'standing' : 'r',\n",
      "        'walk' : 'c',\n",
      "        'walkdown' : 'm',\n",
      "        'walkup' : 'y'}\n",
      "\n",
      "f, (ax1, ax2) = plt.subplots(ncols=2)\n",
      "f.set_size_inches(10, 5)\n",
      "\n",
      "for act, df in numericActivity:\n",
      "    ax1.scatter(df.index, df.ix[:,0], c=cols[act], label=act)\n",
      "    ax2.scatter(df.index, df.ix[:,1], c=cols[act], label=act)\n",
      "\n",
      "ax1.set_ylabel(samsungData.columns[0])\n",
      "ax2.set_ylabel(samsungData.columns[1])\n",
      "ax2.legend(loc='lower right')\n",
      "\n",
      "f.tight_layout();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Homework\n",
      "=========\n",
      "Try hierarchical and k-Means clustering using the iris data set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}